# 4주차 2022 07 18
</br>

## 📌 Machine Learning

###  기계 학습
</br>

<img width="167" alt="스크린샷 2022-07-19 오전 12 38 18" src="https://user-images.githubusercontent.com/40768187/179548891-303bd561-fb57-4d2c-8a29-e5ff6b13edda.png">

</br>

- 데이터가 좋아야 결과가 좋음
- 데이터에서 패턴(규칙)을 찾으며 학습
- 함수 근사: 입력과 출력 관계의 규칙 = 함수

</br>

### 목적

**우리가 가진 데이터가 아닌 다른 데이터를 넣었을 때도 정확도가 있는지** (= 일반화)

</br >

### 전통적인 프로그램 vs. machine learning

<img width="425" alt="image" src="https://user-images.githubusercontent.com/40768187/179550229-5bdad476-f99e-4d33-bb11-c40928980abd.png">

</br>

### 머신러닝 사용할 수 있는 경우

1. 데이터가 있어야 함
2. 데이터에 우리가 관심을 가지는 규칙이 있다고 생각될 때
3. 명시적인 프로그래밍 방법으로는 해결이 안될 때

</br>

### 데이터 형식
1. 정형 데이터 : 표 형식 - 딥러닝보다 빠르고, 정확도(성능)도 비슷하게 나옴
2. 반정형 데이터: xml, html
3. 비정형 데이터: 이미지, 동영상, 음성 - 전통적인(머신러닝) 방식으로는 안함

#### 용어 정리

- column -> feature
- feature 갯수 = 차원의 개수
- sample/인스턴스 = 관측치

ex) 중고차 가격을 예측하는 머신러닝

price - target(종속변수), 나머지 - feature(독립변수)</br>
=> target과 나머지 feature 와의 관계 분석

~~2,3 차원에서 계산하고 증명이 되면, n차원을 넘어감~~

분류 알고리즘 -> tarket = **label**</br>
회귀 알고리즘 -> target

</br>

### 데이터 종류

1. 수치데이터 - 연속형 데이터(키, 몸무게), 이산형 데이터(불량품 수, 판매수량)</br>
2. 범주형데이터 (1등급, 2등급, YES/NO) - 순위형 데이터(등급), 명목형 데이터(성별, 지역)

+) 값 사이에 다른 값이 올 수 있는가? -> 보통 수치데이터

</br>

### 지도 학습 / 비지도 학습

지도 학습: 학습 알고리즘에 주입하는 훈련 데이터에 타깃값(레이블)이라는 원하는 답이 포함되어있는 경우

비지도 학습: 훈련 데이터에 타깃값(레이블)이 없는 학습 방법

#### 지도학습 종류

- 사례기반 학습 (인스턴스): ```k-nn```, 기존 데이터 기억해두고(학습시키고), 새로운 데이터에 대해서는 기존 데이터의 유사도로 예측

    <img width="335" alt="image" src="https://user-images.githubusercontent.com/40768187/179553406-0246631d-a84f-4245-9e03-29931537479c.png">

- 모델 기반: 기존 데이터들의 모델 만들어 예측


#### 지도학습의 대표적인 경우

분류
  - Y 변수가 범주형일 때, 범주 예측
  - 이진 분류(합격/불합격), 다중 분류(혈액형)

회귀
  - Y 변수가 연속형일 때, 수치 예측

#### 선형 분류, 회귀

<img width="358" alt="image" src="https://user-images.githubusercontent.com/40768187/179552616-c394c01e-6052-4b99-ba8a-58cfc6c3ab59.png">

</br>

#### 비지도 학습

군집
- 타깃 변수가 없음
- 특성이 비슷한 데이터들로 묶음

    <img width="393" alt="image" src="https://user-images.githubusercontent.com/40768187/179553425-0395528e-9a99-40a1-bb83-45e65e43ee5f.png">

좋은모델?
- 현재의 데이터를 잘 예측
- **새로운 데이터가 들어왔을 때에도 잘 예측**

</br>

### 과대 적합 (overfitting) VS 과소 적합(underfitting)

모델을 지나치게 복잡하게 학습하여 학습 데이터셋에서는 모델 성능이 높게 나타나지만
정작 새로운 데이터가 주어졌을 때 정확한 예측/분류 수행X

<img width="623" alt="image" src="https://user-images.githubusercontent.com/40768187/179553677-43c3251b-2099-4b40-a02b-7c5b83fdff97.png">

</br>

#### 과적합 막기
- 모델 선택 잘하기
- 데이터 나누기

#### 데이터 나누기?

<img width="532" alt="image" src="https://user-images.githubusercontent.com/40768187/179554445-d428bc7b-400b-4c66-8d58-8a51a7f35502.png">

</br>

```Train Data```, ```Test Data```</br>

학습 완료 모델의 일반화 오차를 추정하기 위해 사용함</br>
새로운 외부 샘플에 대해서 어느 정도 오차가 있을지에 대해 추정

+) 학습 데이터 -> 테스트 데이터 -> 다시 같은 학습 데이터 이렇게 하면 안됨

</br>

```Train Data```, ```Test Data```, ```Validation Data```

검증데이터 - 학습중인 현재 모델의 성능 평가

+) 학습 데이터 -> 테스트 데이터 -> (검증데이터로 학인 ->학습 데이터) 반복

**검증데이터를 테스트할 때마다 바꾸기 -> 똑같으면 다시 검증데이터에서 과적합 발생가능성 있음**

</br>

### 교차 검증

- 가장 적합한 모델 선택을 위한 방법
- 학습 세트를 여러 서브셋으로 나누고, 모델을 각 서브셋의 조합으로 훈련시키고 검증
학습이 끝나면 선택된 모델(최종모델)을 전체 학습 세트로 학습

    <img width="401" alt="image" src="https://user-images.githubusercontent.com/40768187/179554417-6f756ea7-f21d-4990-bd76-79d25bf4205b.png">

</br>

### 라벨 인코딩

- 문자로 표현된 범주형 데이터 숫자로 변환
- 그냥 숫자로 바꾸는 것은 머신러닝에서 숫자가 클수록 영향력이 높다고 판단해서 좋지 않음

#### one-hot encoding (feature 가 늘어남)

<img width="458" alt="image" src="https://user-images.githubusercontent.com/40768187/179555068-ae43fb27-1483-44fc-9a64-ec54e7b53704.png">

</br>
머신러닝 알고리즘이 가까이 있는 두 값이 떨어져 있는 두 값보다 비슷하다고 판단하는 오류 막음

</br>

### 특성 스케일링

<img width="466" alt="image" src="https://user-images.githubusercontent.com/40768187/179555569-d684f3d9-ddb3-4c4f-9edf-b8cfb11fe315.png">

🔝 나이가 커질때 연봉의 값이 급격히 변하는 것을 볼 수 있음
</br>

- feature 들의 크기가 너무 다르면 학습이 잘 되지 않음
- 거리 중심 알고리즘은 스케일링 차이가 크면 학습 잘 되지 않음

#### 방법

1. 표준화: 평균이 0, 분산이 1이 되도록 변환 (일반적으로 많이 씀)

2. 정규화

3. Min-Max Nomarlization: 최댓값 1, 최솟값 0, 나머지 0~1 사이의 값으로 변환 (IMG 처리 때 많이 씀)

</br>

### 이상치(Outlier)

<img width="489" alt="스크린샷 2022-07-19 오전 1 18 26" src="https://user-images.githubusercontent.com/40768187/179556737-6f17487b-4581-4c73-9fc3-3f3f7e9ac3be.png">

</br>
정상 범주에서 크게 벗어난 값

</br>

### 결측치

누락된 값, 비어있는 값

</br>

### 불균형 데이터
-샘플링 기법
 - 오버 샘플링: 소수 클래스의 샘플을 늘림 (Resampling, SMOTE, ADASYN)
 - 언더 샘플링: 다수 클래스의 샘플을 줄임

</br>

### 그 밖

1. 중복값 제거

2. 다중공선성 (선형 회귀)

Ordinary Least Squares(OLS) 즉 최소 제곱법 기반의 회귀 계수 계산은 독립 변수의 독립성에 많은 영향 받음

상관관계가 높은 독립 변수가 많은 경우 독립적인 중요한 독립 변수만을 남기고 제거하거나 규제 적용

PCA를 통해 차원 축소를 수행하는 것도 고려

feature를 제거하는 것은 최후의 방법.

**모델의 성능 평가

분류 - confusion matrix

TP:양성 예측, 정답 양성
FP: 양성 예측 정ㅇ답 음성 -> 0 이 되는게 좋음 ( 스팸메세지가 아닌데 스팸이라 할 때 등)
TN음성 예측 정다 ㅂ 음성
FN음성 예측 정답 양성 -> 0 이 되는게 좋음 (암 데이터 분석 등)

민감도, 정밀도 조정 가능함 분류 알고리즘에선. 데이터마다 민감도, 정밀도를 많이 보는 것이 다름

정밀도, 재현율 Trade off
분류 모델ㅇㅣ 사용될 업무의 특성을 고려하여 정밀도와 재현율 중 더 강조돼야 할 부분을 결정하기 위한
임계값(Threshold)를 조정해 정밀도나 재현율의 수치 높일 수 있음

F1 Score

정밀도와 재현율이 한쪽으로 편향되지 않도록 추가 보완하는 지표
정밀도와 재현율을 하ㅏㄴ의 숫자로 표현

F1 = 2 * (정밀도 *재현율) / (정밀도+재현율)

한쪽이 높아도 다른 한쪽이 낮으면, F1 수치는 높지않다.
----------------------------------------
Threshold와 정확도(Accuracy)
로지스틱 회귀는 모델이 각 클랙스에 속할 확률값을 출력
출력된 값과 Threshold와 비교

TRR 양성 샘플 중 양성으로 나온 것
FPR 음성 샘플 중 양성으로 잘못 나온 것

ROC 
Threshold값 변화시키면서 TPR, FPR을 나타낸 그래프

ROC 커브가 좌 상단에 붙어있는것이 더 좋은 분류기
--------------------------

AUROC
ROC 커브의 면적

회귀 알고리즘

오차(Error) 실젯값과 예측값 차이
회귀 알고리즘은 오차를 최소가 되도록 모델(선의 식) 최적화하는 것

평균 제곱 오차

men squared error
root mean squared error
mean absolute Error - 제일 정확

scoring 이 클수록 좋음
분류는 정확도가 높을 수록 scoring 좋아짐
선형 회귀는 오차이기 때문에 - 붙이고 클수록 scoring 좋아진 것을 알 수 있음

결정 계수 (R 제곱)

독립 변수가 종속 변수를 어느정도 설명하고 있는지 나타내는 지표
R 제곱이 0.3 -> 독립 변수가 종속 변수의 30% 설명

___

Hyper Parameter 튜닝

개발자가 지정해준 파라미터 = Hyper Parameter

- Grid Search, Random Search
- Bayesian Optimization -> 통계?

그리드 서치
모든 범위내에 데이터를 조사 -> 시간 오래 걸림.

랜덤 서치
범위가 너무 넓을때는 격자로 모든 데이터를 학습시키지 않고, 정해준 갯수를 뽑게
해서 학습 시킴 (격자 범위 내에서 100개를 뽑아 학습시키기)

전통적인 머신러닝 알고리즘 배워야하는 이유


___

k-nn

과거의 데이터를 기억하고 (학습), 새로운 데이터에 대해서 가장 가까운 유사도(거리)를 가진 기존 데이터에 따라서 분류
비선형 모델
Y가 범주형일 때 사용
내가 정해주는 파라미터 -> k : 인접한 데이터를 몇개까지 탐색할 거?
			      -> 데이터 사이의 거리는 어떻게 측정할거?

거리 계산
좌표에서 점 사이의 거리 계산 = 유사성 계산

유클리드 거리(많이 씀), 맨하탄 거리

Norm

벡터의 길이 혹은 크기 측정
___

Y 가 연속형의 경우 k-nn

가장 가까이에 있는 데이터의 평균으로 새로운 데이터 예측
평균으로 예측할 시 가장 정확함

___

 k값에 따른 분류

k = 1 인 경우 과대적합 발생
k 값이 커질수록 결정경계가 완만해지지만 과소적합이 발생

___

가장 좋은 k 값 정하는 방법

일정한 범위 내에서 k 값을 조정하여, 가장 좋은 예측 결과 보이는 k값 선정(grid search)

학습 error와 검증 에러가 최소가 되는 k 값을 찾아야한다.

___
SVM

머신러닝에서 가장 인기있는 모델
복잡한 분류 문제 적합
선형, 비선형 분류 모두 사용가능

어떤 직선이 가장 좋은 직선?

2개의 클래스를 분류하는 수많은 직선 중에서 어떤 직선을 골라야 하는가?
아이패드 그림

* 소프트 마진 분류

다변량 데이터의 경우 결정경계가 선이 아니라 면이 됨

* 비선형 SVM 분류 : 커널 트릭

커널을 이용해서 차원 바꿔서 분류
원래의 차원에서는 비선형 분류가 됨

RBF? 다항식?

sklearn parameter

c 클수록 hard margin, 에러 인정x
kernel rbf(가우시안 커널) , linear, poly, sigmoid, ...
degree 다항식 커널의 차수 결정
gamma 클수록 면이 구불거림, 과적합 가능성 증가
coef 상수항

___

